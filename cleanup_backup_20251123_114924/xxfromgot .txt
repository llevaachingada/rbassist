# ðŸ“¦ rbassist â€” Rekordbox Assist Tool (starter repo)

 Drop these files into a new GitHub repo (GitHub Desktop â†’ New Repository), then follow the README.

```
rbassist
â”œâ”€ pyproject.toml
â”œâ”€ README.md
â”œâ”€ .gitignore
â”œâ”€ config
â”‚  â”œâ”€ tags.yml
â”‚  â””â”€ recommend.yml
â”œâ”€ rbassist
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ cli.py
â”‚  â”œâ”€ embed.py
â”‚  â”œâ”€ recommend.py
â”‚  â”œâ”€ bandcamp.py
â”‚  â”œâ”€ utils.py
â”‚  â””â”€ versions.py
â””â”€ data  (auto-created at runtime)
```

---

## pyproject.toml
```toml
[build-system]
requires = [setuptools=68, wheel]
build-backend = setuptools.build_meta

[project]
name = rbassist
version = 0.1.0
description = Rekordbox Assist beatgrid+key helpers, audio similarity, smart crates
authors = [ {name = You} ]
readme = README.md
requires-python = =3.10
dependencies = [
  typer[all]~=0.12,
  rich~=13.7,
  numpy~=1.26,
  librosa~=0.10,
  soundfile~=0.12,
  tqdm~=4.66,
  transformers=4.40,
  accelerate=0.28,
  datasets=2.18,
  hnswlib~=0.8,
  pandas~=2.2,
  pyyaml~=6.0.1
  # NOTE install torchtorchaudio separately for your GPU (see README)
]

[project.scripts]
rbassist = rbassist.cliapp

[tool.setuptools]
packages = [rbassist]
include-package-data = true
```

---

## .gitignore
```gitignore
# Python
__pycache__
.py[cod]
.venv

# Data & model cache
data
.index
.npy
.npz

# VS Code
.vscode
```

---

## configtags.yml
```yaml
# Map your Bandcamp CSV columns to Rekordbox fields  My Tags buckets
columns
  artist artist
  title title
  genre genre
  subgenre subgenre
  tags descriptors

# My Tags categories weâ€™ll derive
mytags
  Genre ${genre}
  Subgenre ${subgenre}
  Descriptors ${tags}

# Standard fields to mirror (optional)
mirror
  Genre ${genre}
  Grouping ${subgenre}
  Comments ${tags}
```

---

## configrecommend.yml
```yaml
embedding
  model m-a-pMERT-v1-330M
  layer_pool last  # or mean25
  sample_rate 24000
  duration_s 120   # seconds per track to embed (set 0 for full)

hnsw
  space cosine
  dim 1024         # MERT feature dim (last layer)
  M 32
  efConstruction 200
  efSearch 64

filters
  tempo_pct 6.0    # +- percent
  allow_doubletime true
  camelot_neighbors true
```

---

## rbassist__init__.py
```python
__all__ = [
    __version__,
]
from .versions import __version__
```

---

## rbassistversions.py
```python
__version__ = 0.1.0
```

---

## rbassistutils.py
```python
from __future__ import annotations
import os, json, math, pathlib
from typing import Iterable, Tuple, Optional
from rich.console import Console
from rich.progress import Progress

console = Console()
ROOT = pathlib.Path(__file__).resolve().parents[1]
DATA = ROOT  data
EMB = DATA  embeddings
IDX = DATA  index
META = DATA  meta.json

for p in (DATA, EMB, IDX)
    p.mkdir(parents=True, exist_ok=True)


def walk_audio(paths Iterable[str]) - list[str]
    exts = {.wav, .flac, .mp3, .m4a, .aiff, .aif}
    files list[str] = []
    for p in paths
        pth = pathlib.Path(p)
        if pth.is_dir()
            for f in pth.rglob()
                if f.suffix.lower() in exts
                    files.append(str(f))
        else
            if pth.suffix.lower() in exts
                files.append(str(p))
    return sorted(files)


def load_meta() - dict
    if META.exists()
        return json.loads(META.read_text(utf-8))
    return {tracks {}}  # path - info


def save_meta(meta dict) - None
    META.write_text(json.dumps(meta, indent=2), encoding=utf-8)


def camelot_compat(k1 Optional[str], k2 Optional[str]) - bool
    if not k1 or not k2 return True
    # Very simple Camelot neighbor check (e.g., 8A neighbors 7A9A8B)
    try
        n1, m1 = int(k1[-1]), k1[-1].upper()
        n2, m2 = int(k2[-1]), k2[-1].upper()
        if k1 == k2 return True
        if m1 == m2 and abs(n1 - n2) == 1 return True
        if n1 == n2 and m1 != m2 return True
    except Exception
        return True
    return False


def tempo_match(bpm1 Optional[float], bpm2 Optional[float], pct float = 6.0, allow_doubletime bool = True) - bool
    if not bpm1 or not bpm2 return True
    if abs(bpm1 - bpm2) = (pct  100.0)  bpm1
        return True
    if allow_doubletime
        if abs(bpm12 - bpm2) = (pct  100.0)  bpm12 return True
        if abs(bpm12 - bpm2) = (pct  100.0)  bpm12 return True
    return False
```

---

## rbassistbandcamp.py
```python
from __future__ import annotations
import csv, pathlib
from typing import Dict, Any
import yaml

# Simple CSV reader + mapping into our meta store

def load_mapping(config_path str  pathlib.Path) - dict
    with open(config_path, r, encoding=utf-8) as f
        return yaml.safe_load(f)


def import_bandcamp(csv_path str, config_path str, meta dict) - dict
    cfg = load_mapping(config_path)
    cols = cfg.get(columns, {})
    with open(csv_path, newline='', encoding=utf-8) as f
        reader = csv.DictReader(f)
        for row in reader
            artist = row.get(cols.get(artist, artist), ).strip()
            title  = row.get(cols.get(title, title), ).strip()
            # We try to find a matching path in meta by Artist - Title
            for path, info in meta.get(tracks, {}).items()
                if (info.get(artist, ).strip().lower(), info.get(title, ).strip().lower()) == (artist.lower(), title.lower())
                    # store tags into info[tags] (list)
                    tags_raw = row.get(cols.get(tags, tags), )
                    tags = [t.strip() for t in tags_raw.replace(;, ,).split(,) if t.strip()]
                    info.setdefault(tags, sorted(set(info.get(tags, []) + tags)))
                    info[genre] = row.get(cols.get(genre, genre)) or info.get(genre)
                    info[subgenre] = row.get(cols.get(subgenre, subgenre)) or info.get(subgenre)
    return meta
```

---

## rbassistembed.py
```python
from __future__ import annotations
import os, pathlib, numpy as np
import librosa, soundfile as sf
from typing import List
from transformers import AutoModel, Wav2Vec2FeatureExtractor
import torch
from rich.progress import track
from .utils import console, EMB, load_meta, save_meta

DEFAULT_MODEL = m-a-pMERT-v1-330M
SAMPLE_RATE = 24000  # per model card

class MertEmbedder
    def __init__(self, model_name str = DEFAULT_MODEL, device str  None = None)
        self.device = device or (cuda if torch.cuda.is_available() else cpu)
        self.model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(self.device)
        self.processor = Wav2Vec2FeatureExtractor.from_pretrained(model_name, trust_remote_code=True)

    def embed(self, audio_path str, duration_s int = 120) - np.ndarray
        y, sr = librosa.load(audio_path, sr=None, mono=True)
        if duration_s and y.shape[0]  sr  duration_s
            y = y[ sr  duration_s]
        if sr != SAMPLE_RATE
            y = librosa.resample(y, orig_sr=sr, target_sr=SAMPLE_RATE)
            sr = SAMPLE_RATE
        inputs = self.processor(y, sampling_rate=sr, return_tensors=pt)
        with torch.no_grad()
            out = self.model({k v.to(self.device) for k, v in inputs.items()}, output_hidden_states=True)
        # Last hidden state mean over time â†’ 1024-d
        feats = out.hidden_states[-1].squeeze(0)  # [T, 1024]
        vec = feats.mean(dim=0).cpu().numpy().astype(np.float32)
        return vec


def build_embeddings(paths List[str], model_name str = DEFAULT_MODEL, duration_s int = 120) - None
    meta = load_meta()
    emb = MertEmbedder(model_name=model_name)
    EMB.mkdir(parents=True, exist_ok=True)
    for p in track(paths, description=Embedding)
        try
            vec = emb.embed(p, duration_s=duration_s)
            out = EMB  (pathlib.Path(p).stem + .npy)
            np.save(out, vec)
            # store meta
            info = meta[tracks].setdefault(p, {})
            info.setdefault(artist, pathlib.Path(p).stem.split( - )[0] if  -  in pathlib.Path(p).stem else )
            info.setdefault(title, pathlib.Path(p).stem.split( - )[-1])
            info[embedding] = str(out)
        except Exception as e
            console.print(f[red]Embedding failed for {p} {e})
    save_meta(meta)
```

---

## rbassistrecommend.py
```python
from __future__ import annotations
import json, pathlib, numpy as np
from typing import List, Tuple
import hnswlib
from rich.table import Table
from rich.console import Console
from .utils import EMB, IDX, META, console, camelot_compat, tempo_match, load_meta

DIM = 1024

class HnswIndex
    def __init__(self, dim int = DIM, space str = cosine)
        self.index = hnswlib.Index(space=space, dim=dim)
        self._built = False

    def build(self, vectors List[np.ndarray], labels List[int], M int = 32, efC int = 200)
        self.index.init_index(max_elements=len(vectors), ef_construction=efC, M=M)
        self.index.add_items(np.vstack(vectors), np.array(labels))
        self.index.set_ef(64)
        self._built = True

    def save(self, path str)
        self.index.save_index(path)

    def load(self, path str)
        self.index.load_index(path)
        self._built = True


def build_index() - None
    meta = load_meta()
    vectors, labels, paths = [], [], []
    for i, (path, info) in enumerate(meta.get(tracks, {}).items())
        epath = info.get(embedding)
        if not epath or not pathlib.Path(epath).exists()
            continue
        vectors.append(np.load(epath))
        labels.append(i)
        paths.append(path)
    if not vectors
        console.print([yellow]No embeddings found. Run rbassist embed build ...)
        return
    idx = HnswIndex(dim=len(vectors[0]))
    idx.build(vectors, labels)
    (IDX  hnsw.idx).parent.mkdir(parents=True, exist_ok=True)
    idx.save(str(IDX  hnsw.idx))
    json.dump(paths, open(IDX  paths.json, w, encoding=utf-8), ensure_ascii=False, indent=2)
    console.print(f[green]Indexed {len(paths)} tracks â†’ {IDX  'hnsw.idx'})


def recommend(seed str, top int = 25, tempo_pct float = 6.0, allow_doubletime bool = True, camelot_neighbors bool = True)
    idxfile = IDX  hnsw.idx
    paths_map = json.load(open(IDX  paths.json, r, encoding=utf-8))
    meta = load_meta()[tracks]
    # resolve seed path
    matches = [p for p in paths_map if seed.lower() in p.lower() or seed.lower() in (meta.get(p,{}).get(artist,) +  -  + meta.get(p,{}).get(title, )).lower()]
    if not matches
        console.print(f[red]Seed not found {seed})
        return
    seed_path = matches[0]
    seed_vec = np.load(meta[seed_path][embedding])  # (1024,)

    # query
    index = hnswlib.Index(space=cosine, dim=seed_vec.shape[0])
    index.load_index(str(idxfile))
    index.set_ef(64)
    labels, dists = index.knn_query(seed_vec, k=top+1)
    labels, dists = labels[0].tolist(), dists[0].tolist()

    # Build table
    table = Table(title=fRecommendations for {seed_path})
    table.add_column(Rank, justify=right)
    table.add_column(Track)
    table.add_column(Artist)
    table.add_column(Title)
    table.add_column(Dist)

    rank = 1
    for label, dist in zip(labels, dists)
        path = paths_map[label]
        if path == seed_path  # skip self
            continue
        info = meta.get(path, {})
        # Simple filters (if bpmkey exist in meta)
        seed_info = meta.get(seed_path, {})
        if camelot_neighbors and not camelot_compat(seed_info.get(key), info.get(key))
            continue
        if not tempo_match(seed_info.get(bpm), info.get(bpm), pct=tempo_pct, allow_doubletime=allow_doubletime)
            continue
        table.add_row(str(rank), path, info.get(artist,), info.get(title,), f{dist.3f})
        rank += 1
        if rank  top
            break
    console.print(table)
```

---

## rbassistcli.py
```python
from __future__ import annotations
import typer, pathlib
from typing import Optional
from rich import print
from .utils import console, walk_audio, load_meta, save_meta
from .embed import build_embeddings
from .recommend import build_index, recommend
from .bandcamp import import_bandcamp

app = typer.Typer(help=Rekordbox Assist (starter))

@app.command(embed-build)
def embed_build(
    path str = typer.Argument(..., help=Folder or file (audio)),
    model str = typer.Option(m-a-pMERT-v1-330M, help=HF model),
    duration int = typer.Option(120, help=Seconds to embed (0=full)),
)
    files = walk_audio([path])
    build_embeddings(files, model_name=model, duration_s=duration)
    console.print([green]Embeddings built.)


@app.command(index)
def index()
    build_index()


@app.command(recommend)
def cmd_recommend(
    seed str = typer.Argument(..., help=Seed path or 'Artist - Title' substring),
    top int = 25,
)
    recommend(seed, top=top)


@app.command(import-tags)
def cmd_import_tags(csv_path str, config str = configtags.yml)
    meta = load_meta()
    meta = import_bandcamp(csv_path, config, meta)
    save_meta(meta)
    console.print([green]Imported Bandcamp tags into local meta (for filteringnotes).n[bold yellow]Note[] Writing My Tags into Rekordbox DB is a separate step.)


if __name__ == __main__
    app()
```

---

## rbassistREADME.md (quickstart extract)
```markdown
# rbassist (starter)

This is a simplified, no-stress starter you can push to GitHub and extend. It
- builds MERT-v1-330M audio embeddings,
- indexes them with HNSWLIB,
- prints simple recommendations, and
- ingests Bandcamp CSV tags into a local meta store for future Rekordbox My Tags writes.

 Rekordbox XML export + My Tags DB writes are not in this minimal starter. Weâ€™ll add them next.

## Install (Windows 11, RTX 4060)

1. Create venv
```powershell
py -3.11 -m venv .venv
. ..venvScriptsActivate.ps1
python -m pip install --upgrade pip
```
2. Install Torch (GPU)
```powershell
pip install torch torchvision torchaudio --index-url httpsdownload.pytorch.orgwhlcu121
```
3. Install package
```powershell
pip install -e .
```

## Use

1) Build embeddings for a folder (reads common audio files)
```powershell
rbassist embed-build DMusicYourCrate
```
2) Build the HNSW index
```powershell
rbassist index
```
3) Get recommendations for a seed track (path or substring)
```powershell
rbassist recommend Artist - Title --top 25
```
4) Import Bandcamp tags (update local meta for filtering later)
```powershell
rbassist import-tags bandcamp.csv
```

Data lives under `data` (embeddings, index, meta.json). This repo is safe to sync to GitHub; keep your audio outside the repo.
